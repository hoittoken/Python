{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyHIGVhfa_Wf"
      },
      "source": [
        "# Стохастический градиентный и координатный спуски"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gn6lluIADUKa"
      },
      "source": [
        "Для каждого задания указано количество баллов (если они оцениваются отдельно) + 1 балл за аккуратное и полное выполнение всего задания"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txCccYvha_Wv"
      },
      "source": [
        "## Загрузка и подготовка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbyOzeZ6a_Wx"
      },
      "source": [
        "**Загрузите уже знакомый вам файл *Advertising.csv* как объект DataFrame.** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Импорт библиотек\n",
        "import numpy as np \n",
        "import pandas as pd "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "E1L4_xeDa_Wz"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>TV</th>\n",
              "      <th>radio</th>\n",
              "      <th>newspaper</th>\n",
              "      <th>sales</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>230.1</td>\n",
              "      <td>37.8</td>\n",
              "      <td>69.2</td>\n",
              "      <td>22.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>44.5</td>\n",
              "      <td>39.3</td>\n",
              "      <td>45.1</td>\n",
              "      <td>10.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>17.2</td>\n",
              "      <td>45.9</td>\n",
              "      <td>69.3</td>\n",
              "      <td>9.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>151.5</td>\n",
              "      <td>41.3</td>\n",
              "      <td>58.5</td>\n",
              "      <td>18.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>180.8</td>\n",
              "      <td>10.8</td>\n",
              "      <td>58.4</td>\n",
              "      <td>12.9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0     TV  radio  newspaper  sales\n",
              "0           1  230.1   37.8       69.2   22.1\n",
              "1           2   44.5   39.3       45.1   10.4\n",
              "2           3   17.2   45.9       69.3    9.3\n",
              "3           4  151.5   41.3       58.5   18.5\n",
              "4           5  180.8   10.8       58.4   12.9"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Подгрузка данных\n",
        "data = pd.read_csv('data/Advertising.csv')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf4aVFndDUKf"
      },
      "source": [
        "**Проверьте, есть ли в данных пропуски и, если они есть - удалите их**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "tiVeFnR5DUKg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 200 entries, 0 to 199\n",
            "Data columns (total 5 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   Unnamed: 0  200 non-null    int64  \n",
            " 1   TV          200 non-null    float64\n",
            " 2   radio       200 non-null    float64\n",
            " 3   newspaper   200 non-null    float64\n",
            " 4   sales       200 non-null    float64\n",
            "dtypes: float64(4), int64(1)\n",
            "memory usage: 7.9 KB\n"
          ]
        }
      ],
      "source": [
        "data = data.dropna()\n",
        "data.info()\n",
        "# Пропуски отсутствуют"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTkiqPr_DUKh"
      },
      "source": [
        "**Преобразуйте ваши признаки в массивы NumPy и разделите их на переменные X (предикторы) и y(целевая переменная)** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "R9OHIRB3a_Xa"
      },
      "outputs": [],
      "source": [
        "# Выделим в качестве целевой переменной признак sales\n",
        "\n",
        "X = data.drop(columns=\"sales\")\n",
        "y = data[\"sales\"]\n",
        "X = np.array(X)\n",
        "y = np.array(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCvjSoHEDUKo"
      },
      "source": [
        "## Координатный спуск (3 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjNm8dATDUKq"
      },
      "source": [
        "**Добавим единичный столбец для того, чтобы у нас был свободный коэффициент в уравнении регрессии:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "LMgq0fmKDUKr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(200, 5) (200, 1)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "X = np.hstack([np.ones(X.shape[0]).reshape(-1, 1), X])\n",
        "y = y.reshape(-1, 1)\n",
        "print(X.shape, y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R008OQwcDUKt"
      },
      "source": [
        "**Нормализуем данные: обычно это необходимо для корректной работы алгоритма**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "2Sk7Wx-SDUKt"
      },
      "outputs": [],
      "source": [
        "X = X / np.sqrt(np.sum(np.square(X), axis=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_pHHbAdDUKu"
      },
      "source": [
        "**Реализуйте алгоритм координатного спуска:** (3 балла)\n",
        "\n",
        "Ниже приведен алгоритм координатного спуска для случая нормализованных данных:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Задано:**\n",
        "\n",
        "* $X=(x_{ij})$ - матрица наблюдений, размерностью $dim(X)=(m, n)$\n",
        "* $N=1000$ - количество итераций\n",
        "\n",
        "**Примечание:** *1000 итераций здесь указаны для этого задания, на самом деле их может быть намного больше, нет детерменированного значения.*\n",
        "\n",
        "**Алгоритм (математическая запись):**\n",
        "* Создать нулевой вектор параметров $w_0=(0, 0,..., 0)^T$\n",
        "* Для всех $t=1, 2, ..., N$ итераций:\n",
        "    * Для всех $k = 1, 2,..., n$:\n",
        "        * Фиксируем значение всех признаков, кроме $k$-ого и вычисляем прогноз модели линейной регрессии.Для этого исключаем признак $k$-ый из данных и $w_j$ из параметров при построении прогноза.\n",
        "        Математически это можно записать следующим образом:\n",
        "\n",
        "        $$h_i = \\sum_{j=1}^{k-1} x_{ij}w_{j} + \\sum_{j=k+1}^{n} x_{ij}w_j $$\n",
        "\n",
        "        **Примечание:**\n",
        "        \n",
        "        *Обратите, что в данной записи текущий признак под номером $k$ не участвует в сумме.Сравните эту запись с классической записью прогноза линейной регрессии в случае нормированных данных (когда участвуют все признаки):*\n",
        "\n",
        "        $$h_i = \\sum_{j=1}^{n} x_{ij}w_{j}$$ \n",
        "        \n",
        "        * Вычисляем новое значение параметра $k$-ого коэффициента: \n",
        "        $$w_k = \\sum_{i=1}^{m} x_{ik} (y_i - h_i) = x_k^T(y-h) $$\n",
        "\n",
        "    * Вычисляем значение функции потерь и сохраняем в историю изменения функции потерь (В оценке функции потерь участвуют все признаки):\n",
        "        $$\\hat{y_i} = \\sum_{j=1}^{n}x_{ij}w_j$$\n",
        "        $$Loss_t = \\frac{1}{n} \\sum_{i=1}^{m}(y_i-\\hat{y_i})^2$$\n",
        "        \n",
        "        или в векторном виде:\n",
        "        \n",
        "        $$\\hat{y} = Xw$$\n",
        "        $$Loss_t = \\frac{1}{n}(y-\\hat{y})^T(y-\\hat{y})$$\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Алгоритм (псевдокод):**\n",
        "```python\n",
        "\n",
        "num_iters = #количество итераций\n",
        "m = # количество строк в матрице X\n",
        "n = # количество столбцов в матрице X\n",
        "w = #вектор размера nx1, состояющий из нулей\n",
        "\n",
        "for i in range(num_iters):\n",
        "    for k in range(n):\n",
        "        # Вычисляем прогноз без k-ого фактора\n",
        "        h = (X[:,0:k] @ w[0:k]) + (X[:,k+1:] @ w[k+1:])\n",
        "        # Обновляем новое значение k-ого коэффициента\n",
        "        w[k] =  (X[:,k].T @ (y - h))\n",
        "        # Вычисляем функцию потерь\n",
        "        cost = sum((X @ w) - y) ** 2)/(len(y))\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3IdiHm9DUKv"
      },
      "source": [
        "Вам необходимо реализовать координатный спуск, и вывести веса в модели линейной регрессии."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_iters = 1000 #количество итераций\n",
        "m = len(X) # количество строк в матрице X\n",
        "n = len(X[0]) # количество столбцов в матрице X\n",
        "w = np.zeros((n,1)) #вектор размера nx1, состояющий из нулей\n",
        "\n",
        "for i in range(num_iters):\n",
        "    for k in range(n):\n",
        "        # Вычисляем прогноз без k-ого фактора\n",
        "        h = (X[:,0:k] @ w[0:k]) + (X[:,k+1:] @ w[k+1:])\n",
        "        # Обновляем новое значение k-ого коэффициента\n",
        "        w[k] = (X[:,k].T @ (y - h))\n",
        "        # Вычисляем функцию потерь\n",
        "        cost = sum(((X @ w) - y) ** 2)/(len(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 42.5000792   -0.95040482 110.15857249  73.47133693  -0.65919361]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "w_h = np.squeeze(np.transpose(w))\n",
        "print(w_h)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3jG-7UADUKx"
      },
      "source": [
        "Сравните результаты с реализацией линейной регрессии из библиотеки sklearn:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "SBl-1Yb5DUKy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 42.5000792   -0.95040482 110.15857249  73.47133693  -0.65919361]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        " \n",
        "model = LinearRegression(fit_intercept=False)\n",
        "model.fit(X, y)\n",
        " \n",
        "print(model.coef_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIl0AGLyDUKy"
      },
      "source": [
        "Если вы все сделали верно, они должны практически совпасть!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Вывод: коэффициенты линейной регрессии и координатоного спуска совпали"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCGwFnPdDUKz"
      },
      "source": [
        "## Стохастический градиентный спуск (6 баллов)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u7Q2YJla_Xk"
      },
      "source": [
        "**Отмасштабируйте столбцы исходной матрицы *X* (которую мы не нормализовали еще!). Для того, чтобы это сделать, надо вычесть из каждого значения среднее и разделить на стандартное отклонение** (0.5 баллов)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "9cEpV_5La_Xo"
      },
      "outputs": [],
      "source": [
        "X = data.drop('sales', axis=1)\n",
        "X = np.array(X)\n",
        "\n",
        "X = (X - np.mean(X))/np.std(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WkNYILHDUK1"
      },
      "source": [
        "**Добавим единичный столбец**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "EVl5tEGtDUK1"
      },
      "outputs": [],
      "source": [
        "X = np.hstack([np.ones(X.shape[0]).reshape(-1, 1), X])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m53tZA5fDUK1"
      },
      "source": [
        "**Создайте функцию mse_error для вычисления среднеквадратичной ошибки, принимающую два аргумента: реальные значения и предсказывающие, и возвращающую значение mse** (0.5 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpOLhdvBDUK2"
      },
      "source": [
        "**Сделайте наивный прогноз: предскажите продажи средним значением. После этого рассчитайте среднеквадратичную ошибку для этого прогноза** (0.5 балла)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "kLV_XljVa_YZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Наивный прогноз (среднее значение продаж): [14.0225]\n",
            "Среднеквадратичная ошибка (MSE) для наивного прогноза: 27.085743750000002\n"
          ]
        }
      ],
      "source": [
        "def mse_error(y_pred, y):\n",
        "    mse = ((y - y_pred) ** 2).mean()\n",
        "    return mse # Вычисляем среднее значение реальных продаж\n",
        "mean_sales = np.mean(y)\n",
        "\n",
        "# Создаем прогноз, предсказывая все продажи средним значением\n",
        "y_pred = np.full_like(y, mean_sales)\n",
        "\n",
        "mse = mse_error(y, y_pred)\n",
        "\n",
        "print(\"Наивный прогноз (среднее значение продаж):\", y_pred[0])\n",
        "print(\"Среднеквадратичная ошибка (MSE) для наивного прогноза:\", mse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbybL2ola_ZM"
      },
      "source": [
        "**Создайте функцию *lin_pred*, которая может по матрице предикторов *X* и вектору весов линейной модели *w* получить вектор прогнозов** (0.5 балла)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "1Cyz-Luaa_ZO"
      },
      "outputs": [],
      "source": [
        "\n",
        "def lin_pred(X,w):\n",
        "    res = np.zeros([len(X),1])\n",
        "    for i in range(len(X)):\n",
        "        res[i] = (np.dot(w,X[i]))\n",
        "    return res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BU4adBrya_Zm"
      },
      "source": [
        "**Создайте функцию *stoch_grad_step* для реализации шага стохастического градиентного спуска. (1.5 балла) \n",
        "Функция должна принимать на вход следующие аргументы:**\n",
        "* матрицу *X*\n",
        "* вектора *y* и *w*\n",
        "* число *train_ind* - индекс объекта обучающей выборки (строки матрицы *X*), по которому считается изменение весов\n",
        "* число *$\\eta$* (eta) - шаг градиентного спуска\n",
        "\n",
        "Результатом будет вектор обновленных весов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyLY-P02DUK5"
      },
      "source": [
        "Шаг для стохастического градиентного спуска выглядит следующим образом:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORsAyIKNDUK5"
      },
      "source": [
        "$$\\Large w_j \\leftarrow w_j - \\frac{2\\eta}{\\ell} \\sum_{i=1}^\\ell{{x_{ij}((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQl2FrpuDUK6"
      },
      "source": [
        "Для того, чтобы написать функцию, нужно сделать следующее:\n",
        "    \n",
        "*  посчитать направление изменения: умножить объект обучающей выборки на 2 и на разницу между предсказанным значением и реальным, а потом поделить на количество элементов в выборке.\n",
        "* вернуть разницу между вектором весов и направлением изменения, умноженным на шаг градиентного спуска"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "YUhVQGsja_Zn"
      },
      "outputs": [],
      "source": [
        "def stoch_grad_step(X, y, w, train_ind, eta):\n",
        "    x_element = X[train_ind] # элемент с рандомным индексом\n",
        "    y_element = y[train_ind]\n",
        "    gradient = 2 * x_element.T * ((lin_pred(x_element, w)) - y_element) / X.shape[0]\n",
        "    w_new = w - gradient * eta\n",
        "    return w_new"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXwIFd0Ma_Zx"
      },
      "source": [
        "**Создайте функцию *stochastic_gradient_descent*, для реализации стохастического градиентного спуска (2.5 балла)**\n",
        "\n",
        "**Функция принимает на вход следующие аргументы:**\n",
        "- Матрицу признаков X\n",
        "- Целевую переменнную\n",
        "- Изначальную точку (веса модели)\n",
        "- Параметр, определяющий темп обучения\n",
        "- Максимальное число итераций\n",
        "- Евклидово расстояние между векторами весов на соседних итерациях градиентного спуска,при котором алгоритм прекращает работу \n",
        "\n",
        "**На каждой итерации в вектор (список) должно записываться текущее значение среднеквадратичной ошибки. Функция должна возвращать вектор весов $w$, а также вектор (список) ошибок.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVeoNF1JDUK7"
      },
      "source": [
        "Алгоритм сследующий:\n",
        "    \n",
        "* Инициализируйте расстояние между векторами весов на соседних итерациях большим числом (можно бесконечностью)\n",
        "* Создайте пустой список для фиксации ошибок\n",
        "* Создайте счетчик итераций\n",
        "* Реализуйте оновной цикл обучения пока расстояние между векторами весов больше того, при котором надо прекратить работу (когда расстояния станут слишком маленькими - значит, мы застряли в одном месте) и количество итераций меньше максимально разрешенного: сгенерируйте случайный индекс, запишите текущую ошибку в вектор ошибок, запишите в переменную текущий шаг стохастического спуска с использованием функции, написанной ранее. Далее рассчитайте текущее расстояние между векторами весов и прибавьте к счетчику итераций 1.\n",
        "* Верните вектор весов и вектор ошибок"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "CD_xcFNfa_Zy"
      },
      "outputs": [],
      "source": [
        "# Алгоритм стохастического градиентного спуска\n",
        "from random import randint\n",
        "\n",
        "def stochastic_gradient_step(X, y, w, train_ind, eta):\n",
        "    \"\"\"\n",
        "    Perform a stochastic gradient step.\n",
        "\n",
        "    Parameters:\n",
        "    - X: numpy array of shape (n_samples, n_features) representing the input features.\n",
        "    - y: numpy array of shape (n_samples,) representing the target values.\n",
        "    - w: numpy array of shape (n_features,) representing the weights.\n",
        "    - train_ind: index of the selected sample.\n",
        "    - eta: learning rate for the gradient update.\n",
        "\n",
        "    Returns:\n",
        "    - weights: updated weights after the stochastic gradient step.\n",
        "    \"\"\"\n",
        "\n",
        "    n_samples, n_features = X.shape\n",
        "\n",
        "    x_sample = X[train_ind]\n",
        "    y_sample = y[train_ind]\n",
        "    \n",
        "    y_pred = x_sample@w\n",
        "    gradient = 2*x_sample*(y_pred-y_sample)/n_samples\n",
        "    weights = w - eta * gradient\n",
        "\n",
        "    return weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OqHO1Rta_Z7"
      },
      "source": [
        " **Запустите $10^5$ итераций стохастического градиентного спуска. Укажите вектор начальных весов, состоящий из нулей. Можете поэкспериментировать с параметром, отвечающим за темп обучения.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6fHHT6vDUK8"
      },
      "source": [
        "**Постройте график зависимости ошибки от номера итерации**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [],
      "source": [
        "def stochastic_gradient_descent(X, y, init_w, eta, max_iter, distance_metric):\n",
        "    \"\"\"\n",
        "    Perform stochastic gradient descent.\n",
        "\n",
        "    Parameters:\n",
        "    - X: numpy array of shape (n_samples, n_features) representing the input features.\n",
        "    - y: numpy array of shape (n_samples,) representing the target values.\n",
        "    - init_w: numpy array of shape (n_features,) representing the initial weights.\n",
        "    - eta: learning rate for the gradient update.\n",
        "    - max_iter: number of iters (iterations) to run stochastic gradient descent.\n",
        "    - distance_metric: threshold for stopping the algorithm based on a specified distance metric.\n",
        "\n",
        "    Returns:\n",
        "    - weights: weights vector on which the method converged.\n",
        "    - errors: list of errors at each iter.\n",
        "    \"\"\"\n",
        "\n",
        "    # Инициализируем расстояние между векторами весов на соседних\n",
        "    # итерациях большим числом. \n",
        "    distance = np.inf\n",
        "    # Инициализируем вектор весов   \n",
        "    weights = init_w\n",
        "    # Список для фиксации ошибок \n",
        "    errors = []\n",
        "    # Счетчик итераций\n",
        "    iter_num = 0\n",
        "\n",
        "    while distance > distance_metric and iter_num < max_iter:\n",
        "        weights_current = weights\n",
        "        # Генерируем случай индекс \n",
        "        random_ind = np.random.randint(X.shape[0])\n",
        "        \n",
        "        # Применяем функции созданные ранее \n",
        "        weights = stochastic_gradient_step(X, y, weights, random_ind, eta)\n",
        "        errors.append(mse_error(y, lin_pred(X, weights)))\n",
        "        \n",
        "        # Вычисляем растояние между векторами для проверки\n",
        "        distance = np.linalg.norm(weights_current - weights)\n",
        "        iter_num += 1\n",
        "\n",
        "    return weights, errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "zsSfHDzLDUK9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'MSE')"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "w, errors = stochastic_gradient_descent(X, y, np.zeros(X.shape[1]), 2, 1e+5, 1e-8)\n",
        "\n",
        "import plotly as plt\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "fig = plt.figure(figsize=(7, 3))\n",
        "\n",
        "ax = fig.add_axes([0, 0, 1, 1])\n",
        "ax.plot(range(len(errors)), errors)\n",
        "ax.set_xlabel('Iteration number')\n",
        "ax.set_ylabel('MSE')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-MVOcJ6a_aY"
      },
      "source": [
        "**Выведите вектор весов, к которому сошелся метод.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "MPjVkXe4DUK9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[20.50401019  0.0453926   3.51932436 13.73464079  0.10646034]\n"
          ]
        }
      ],
      "source": [
        "print(w)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qabzMc3Qa_a5"
      },
      "source": [
        "**Выведите среднеквадратичную ошибку на последней итерации.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "7tPWleMIa_a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.8446927189879636\n"
          ]
        }
      ],
      "source": [
        "print(errors[-1])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Практика_Оптимизация.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.10.8 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "86c56a74836ad344b00594bf6f38fa6a676a207ceefe20d101fbc465800ccb8d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
