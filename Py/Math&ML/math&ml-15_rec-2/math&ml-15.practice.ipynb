{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5495530808754976"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ЗАДАНИЕ 2.1\n",
    "\n",
    "(1.1 * 5.1 + 2.3 * 6.2 + 5.1 * 1.1) / ((1.2**2 + 2.3**2 + 5.1**2)**0.5 * (5.1**2 + 6.2**2 + 1.1**2)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7787, 17905)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ЗАДАНИЕ 2.2\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "df = pd.read_csv('netflix_titles.zip')\n",
    "model = TfidfVectorizer(stop_words='english')\n",
    "df['description'] = df['description'].fillna('')\n",
    "feature_matrix = model.fit_transform(df['description'])\n",
    "\n",
    "feature_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "cosine_sim = linear_kernel(feature_matrix, feature_matrix)\n",
    "indices = pd.Series(df.index,index=df['title']).drop_duplicates()\n",
    "\n",
    "def get_recommendations(title):\n",
    "    idx = indices[title]\n",
    "    #вычисляем попарные коэффициенты косинусной близости\n",
    "    scores = list(enumerate(cosine_sim[idx]))\n",
    "    #сортируем фильмы на основании коэффициентов косинусной близости по убыванию\n",
    "    scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "    #выбираем десять наибольших значений косинусной близости; нулевую не берём, т. к. это тот же фильм\n",
    "    scores =   scores[1:11]\n",
    "    #забираем индексы\n",
    "    ind_movie = [i[0] for i in scores]\n",
    "    #возвращаем названия по индексам\n",
    "    return df['title'].iloc[ind_movie]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "709                Balto 2: Wolf Quest\n",
       "7446                           Vroomiz\n",
       "1338    Chilling Adventures of Sabrina\n",
       "7388                          Vampires\n",
       "1770                          Dinotrux\n",
       "2767                     Hold the Dark\n",
       "5540                 Shanghai Fortress\n",
       "4041                             Mercy\n",
       "2582                       Half & Half\n",
       "1365        Christmas in the Heartland\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ЗАДАНИЕ 2.3\n",
    "\n",
    "get_recommendations('Balto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.dataset import BUILTIN_DATASETS #с помощью данного объекта мы можем использовать встроенные датасеты\n",
    "\n",
    "data = Dataset.load_from_file(\n",
    "    \"u.data.txt\",\n",
    "    reader=Reader(line_format=\"user item rating timestamp\", sep=\"\\t\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data.raw_ratings, columns=['userId', 'movieId', 'rating', 'timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЗАДАНИЕ 3.1\n",
    "\n",
    "df.apply('nunique')\n",
    "\n",
    "# 1682"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЗАДАНИЕ 3.2\n",
    "\n",
    "df.apply('nunique')\n",
    "\n",
    "# 943"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЗАДАНИЕ 3.3\n",
    "\n",
    "df['rating'].value_counts()\n",
    "\n",
    "# 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# в collab загрузим файл `u.data.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-surprise\n",
    "import pandas as pd\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.dataset import BUILTIN_DATASETS #с помощью данного объекта мы можем использовать встроенные датасеты\n",
    "\n",
    "data = Dataset.load_from_file(\n",
    "    \"u.data.txt\",\n",
    "    reader=Reader(line_format=\"user item rating timestamp\", sep=\"\\t\"),\n",
    ")\n",
    "\n",
    "df = pd.DataFrame(data.raw_ratings, columns=['userId', 'movieId', 'rating', 'timestamp'])\n",
    "\n",
    "from surprise.model_selection import train_test_split\n",
    "trainset, testset = train_test_split(data, test_size=0.25, random_state=13)\n",
    "len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЗАДАНИЕ 3.4\n",
    "\n",
    "from surprise.model_selection import train_test_split\n",
    "trainset, testset = train_test_split(data, test_size=0.25, random_state=13)\n",
    "len(testset)\n",
    "\n",
    "# 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЗАДАНИЕ 3.5\n",
    "\n",
    "from surprise import SVD, KNNBasic, accuracy\n",
    "sim_options = {\n",
    "    'name': 'cosine',\n",
    "    'user_based': False\n",
    "}\n",
    " \n",
    "knn = KNNBasic(sim_options=sim_options)\n",
    "knn.fit(trainset)\n",
    "predictions = knn.test(testset)\n",
    "predictions\n",
    "\n",
    "#1.\n",
    "\n",
    "for prediction in predictions:\n",
    "    if prediction.uid == '500' and prediction.iid == '699':\n",
    "        print(prediction.r_ui)\n",
    "        print(round(prediction.est, 2))\n",
    "        break\n",
    "    \n",
    "# 3    \n",
    "    \n",
    "# 2.\n",
    "uid = str(500)\n",
    "iid = str(699)  \n",
    "pred = knn.predict(uid, iid, verbose=True)\n",
    "\n",
    "# 3.47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЗАДАНИЕ 3.6\n",
    "\n",
    "sim_options = {\n",
    "    'name': 'cosine',\n",
    "    'user_based': True\n",
    "}\n",
    "knn = KNNBasic(sim_options=sim_options)\n",
    "knn.fit(trainset)\n",
    "predictions = knn.test(testset)\n",
    "accuracy.rmse(predictions)\n",
    "\n",
    "# 1.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ЗАДАНИЕ 3.7\n",
    "\n",
    "model = SVD()\n",
    "model.fit(trainset)\n",
    "predictions = model.test(testset)\n",
    "accuracy.rmse(predictions)\n",
    "\n",
    "# 0.94"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Юнит 4\n",
    "\n",
    "https://colab.research.google.com/drive/1iZywtz2wiT8b1QvafcKURkzb4y2rEd0G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightfm\n",
    "!pip install scipy==1.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm import LightFM\n",
    "from lightfm.cross_validation import random_train_test_split\n",
    "from lightfm.evaluation import precision_at_k, recall_at_k\n",
    "import pandas as pd \n",
    "\n",
    "ratings = pd.read_csv('ratings.csv') # Поставленные оценки\n",
    "books = pd.read_csv('books.csv') # Информация о книгах\n",
    "tags = pd.read_csv('tags.csv') # Информация о тегах\n",
    "book_tags = pd.read_csv('book_tags.csv') # Книги с тегами "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ЗАДАНИЕ 4.1\n",
    "\n",
    "dict_map = dict(zip(books.goodreads_book_id,books.book_id))\n",
    "book_tags['id'] = book_tags.goodreads_book_id.apply(lambda x: dict_map[x])\n",
    " \n",
    "book_tags[book_tags['goodreads_book_id']==5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ЗАДАНИЕ 4.2\n",
    "\n",
    "book_tags = book_tags[book_tags.tag_id.isin(tags.tag_id)]\n",
    "book_tags.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "\n",
    "ratings_matrix = csr_matrix((ratings.rating,(ratings.user_id,ratings.book_id))) # Передаём в качестве аргументов в функцию выставленный рейтинг (это будут значения матрицы), а также id пользователя и id книги (это будут индексы для строк и столбцов матрицы)\n",
    "\n",
    "meta_matrix  = csr_matrix(([1]*len(book_tags),(book_tags.id,book_tags.tag_id.astype(\"int\")))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ЗАДАНИЕ 4.4\n",
    "\n",
    "ratings_matrix.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LightFM(\n",
    "    loss='warp-kos', # Определяем функцию потерь\n",
    "    random_state=42, # Фиксируем случайное разбиение\n",
    "    learning_rate=0.05, # Темп обучения\n",
    "    no_components=100 # Размерность вектора для представления данных в модели\n",
    ")\n",
    "\n",
    "train, test = random_train_test_split(\n",
    "    ratings_matrix, # Общая выборка\n",
    "    test_percentage=0.2, # Размер тестовой выборки\n",
    "    random_state=42 # Генератор случайных чисел\n",
    ")\n",
    "\n",
    "model = model.fit(\n",
    "    train, # Обучающая выборка\n",
    "    item_features=meta_matrix, # Признаки товаров\n",
    "    epochs=10, # Количество эпох\n",
    "    verbose=True # Отображение обучения\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ЗАДАНИЕ 4.5\n",
    "\n",
    "prec_score = precision_at_k(\n",
    "                     model,\n",
    "                     test,\n",
    "                     item_features = meta_matrix).mean() \n",
    "print(prec_score)\n",
    "\n",
    "scores = model.predict(<индекс интересующего пользователя>, np.arange(n_items),user_features=new_user_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.arange(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
